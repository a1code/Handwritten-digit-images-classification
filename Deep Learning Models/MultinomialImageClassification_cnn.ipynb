{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "MultinomialImageClassification_cnn.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERl7-jmJMce_"
      },
      "source": [
        "Based on my learnings from the Deep Learning Specialization offered by [deeplearning.ai](https://www.coursera.org/specializations/deep-learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J30cf3KOb9rk"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from urllib import request\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAW70XaXcG3W",
        "outputId": "95968ebf-16fa-4e2f-ce11-d4cdcf78d960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Loading the dataset\n",
        "\n",
        "filename = [\n",
        "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
        "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
        "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
        "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
        "]\n",
        "\n",
        "def download_mnist():\n",
        "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
        "    for name in filename:\n",
        "        print(\"Downloading \"+name[1])\n",
        "        request.urlretrieve(base_url+name[1], name[1])\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "def save_mnist():\n",
        "    mnist = {}\n",
        "    for name in filename[:2]:\n",
        "        with gzip.open(name[1], 'rb') as f:\n",
        "            temp_x = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
        "            mnist[name[0]] = temp_x.reshape(temp_x.shape[0], 28, 28, 1)\n",
        "    for name in filename[-2:]:\n",
        "        with gzip.open(name[1], 'rb') as f:\n",
        "            temp_y = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "            mnist[name[0]] = temp_y.reshape(1, temp_y.shape[0])\n",
        "    with open(\"mnist.pkl\", 'wb') as f:\n",
        "        pickle.dump(mnist,f)\n",
        "    print(\"Save complete.\")\n",
        "\n",
        "def load_dataset():\n",
        "    with open(\"mnist.pkl\",'rb') as f:\n",
        "        mnist = pickle.load(f)\n",
        "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
        "\n",
        "download_mnist()\n",
        "save_mnist()\n",
        "\n",
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_dataset()\n",
        "num_classes = len(np.unique(Y_test_orig))\n",
        "\n",
        "print (\"X_train_orig shape: \" + str(X_train_orig.shape))\n",
        "print (\"Y_train_orig shape: \" + str(Y_train_orig.shape))\n",
        "print (\"X_test_orig shape: \" + str(X_test_orig.shape))\n",
        "print (\"Y_test_orig shape: \" + str(Y_test_orig.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz\n",
            "Downloading t10k-images-idx3-ubyte.gz\n",
            "Downloading train-labels-idx1-ubyte.gz\n",
            "Downloading t10k-labels-idx1-ubyte.gz\n",
            "Download complete.\n",
            "Save complete.\n",
            "X_train_orig shape: (60000, 28, 28, 1)\n",
            "Y_train_orig shape: (1, 60000)\n",
            "X_test_orig shape: (10000, 28, 28, 1)\n",
            "Y_test_orig shape: (1, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RDRgrVBcKZg",
        "outputId": "ce3ec93c-2898-4814-a2cd-db35fa0f83b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Example of a picture\n",
        "index = 4\n",
        "plt.imshow((X_train_orig[index,:,:,:]).reshape(28,28))\n",
        "print (\"y = \" + str(np.squeeze(Y_train_orig[:,index])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y = 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn0zRG6ocNXX"
      },
      "source": [
        "# this function encodes true label vector with one-hot encoding\n",
        "\n",
        "def convert_to_one_hot(Y_raw, C):\n",
        "  \"\"\"\n",
        "    Encode true label vector with one-hot encoding\n",
        "    \n",
        "    Arguments:\n",
        "    Y_raw -- true label vector, size: (1, number of training examples)\n",
        "    C -- number of possible classes for labels\n",
        "\n",
        "    Returns:\n",
        "    Y -- one-hot encoded \"true\" label vector, shape: (number of classes, number of examples)\n",
        "  \"\"\"\n",
        "    \n",
        "  Y = np.eye(C)[Y_raw.reshape(-1)].T\n",
        "  return Y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKBxITCDcQub",
        "outputId": "f24702b9-2f79-4d99-db11-5418abed9823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Normalize image vectors\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, num_classes).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, num_classes).T\n",
        "\n",
        "print (\"number of label classes = \" + str(num_classes))\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of label classes = 10\n",
            "number of training examples = 60000\n",
            "number of test examples = 10000\n",
            "X_train shape: (60000, 28, 28, 1)\n",
            "Y_train shape: (60000, 10)\n",
            "X_test shape: (10000, 28, 28, 1)\n",
            "Y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXwxLVNqcT64"
      },
      "source": [
        "# this function creates placeholders for input image X and output Y\n",
        "\n",
        "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session\n",
        "    \n",
        "    Arguments:\n",
        "    n_H0 -- scalar, height of an input image\n",
        "    n_W0 -- scalar, width of an input image\n",
        "    n_C0 -- scalar, number of channels in the input image\n",
        "    n_y -- scalar, number of classes\n",
        "        \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, shape: [None, n_H0, n_W0, n_C0]\n",
        "    Y -- placeholder for the input labels, shape: [None, n_y]\n",
        "    \"\"\"\n",
        "\n",
        "    X = tf.compat.v1.placeholder(tf.float32, (None, n_H0, n_W0, n_C0))\n",
        "    Y = tf.compat.v1.placeholder(tf.float32, (None, n_y))\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKH3CkOgcXPq"
      },
      "source": [
        "# this function initilizes model parameters for the CNN\n",
        "\n",
        "def initialize_parameters(n_C0):\n",
        "    \"\"\"\n",
        "    Initializes weight parameters of the kernels/filters for convolutional layers in the model:\n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "    \n",
        "    Arguments:\n",
        "    n_C0 -- scalar, number of channels in the input image\n",
        "\n",
        "    Returns:\n",
        "    parameters -- dictionary of tensors containing W1, W2\n",
        "    \"\"\"\n",
        "    \n",
        "    W1 = tf.compat.v1.get_variable(\"W1\", [4, 4, n_C0, 8], tf.float32, \n",
        "                                   tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\", seed = 0))\n",
        "    W2 = tf.compat.v1.get_variable(\"W2\", [2, 2, 8, 16], tf.float32, \n",
        "                                   tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\", seed = 0))\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"W2\": W2}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ewH2XQ5caw8"
      },
      "source": [
        "# this function implements forward propagation through all the layers\n",
        "\n",
        "def forward_propagation(X, parameters, n_y):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model:\n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "    \n",
        "    Note that for simplicity and grading purposes, we'll hard-code some values\n",
        "    such as the stride and kernel (filter) sizes. \n",
        "    Normally, functions should take these values as function parameters.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, shape: (input size, number of examples)\n",
        "    parameters -- dictionary containing model parameters \"W1\", \"W2\"\n",
        "    n_y -- scalar, number of classes\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    \n",
        "    # CONV2D: stride of 1, padding 'SAME'\n",
        "    Z1 = tf.nn.conv2d(input=X, filters=W1, strides = [1,1,1,1], padding = 'SAME')\n",
        "    # RELU\n",
        "    A1 = tf.nn.relu(Z1)\n",
        "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
        "    P1 = tf.nn.max_pool2d(input=A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
        "\n",
        "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
        "    Z2 = tf.nn.conv2d(input=P1, filters=W2, strides = [1,1,1,1], padding = 'SAME')\n",
        "    # RELU\n",
        "    A2 = tf.nn.relu(Z2)\n",
        "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
        "    P2 = tf.nn.max_pool2d(input=A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
        "\n",
        "    # FLATTEN\n",
        "    F = tf.compat.v1.layers.flatten(P2)\n",
        "\n",
        "    # FULLY-CONNECTED without non-linear activation function\n",
        "    # number of hidden units in the output layer corresponds to number of label classes\n",
        "    Z3 = tf.compat.v1.layers.dense(F, n_y, activation=None)\n",
        "\n",
        "    return Z3"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkpcGJl5ceRm"
      },
      "source": [
        "# this function computes the cross-entropy cost\n",
        "\n",
        "def compute_cost(Z3, Y):\n",
        "    \"\"\"\n",
        "    Computes the softmax cross-entropy cost for multinomial classification\n",
        "    \n",
        "    Arguments:\n",
        "    Z3 -- output of forward propagation (output of the last LINEAR unit), shape: (number of examples, number of classes)\n",
        "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "    \n",
        "    Returns:\n",
        "    cost - Tensor of the cost function\n",
        "    \"\"\"\n",
        "    \n",
        "    cost = tf.reduce_mean(input_tensor=tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = tf.stop_gradient( Y)))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2XAvv2qciYV"
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 500):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, shape: (m, Hi, Wi, Ci)\n",
        "    Y -- true \"label\" vector, shape: (m, n_y)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    \n",
        "    # Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation,:,:,:]\n",
        "    shuffled_Y = Y[permutation,:]\n",
        "\n",
        "    # Partition (shuffled_X, shuffled_Y)\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvlb6ZvRcmnJ"
      },
      "source": [
        "# this function implements the 3-layer CNN model\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
        "          num_epochs = 100, minibatch_size = 500, print_cost = True):\n",
        "    \"\"\"\n",
        "    Implements a three-layer ConvNet in Tensorflow:\n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set\n",
        "    Y_train -- test set\n",
        "    X_test -- training set\n",
        "    Y_test -- test set\n",
        "    learning_rate -- determines step sizes during optimization, scalar\n",
        "    num_epochs -- number of passes over the training set during optimization\n",
        "    mini_batch_size -- the size of a mini batch    \n",
        "    print_cost -- True to print the cost every 5 epochs\n",
        "    \n",
        "    Returns:\n",
        "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
        "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
        "    parameters -- parameters learnt by the model; used for making predictions\n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
        "    n_y = Y_train.shape[1]                      \n",
        "    costs = []                                        # To keep track of the cost\n",
        "        \n",
        "\n",
        "    # Create Placeholders of the correct shape\n",
        "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
        "\n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters(n_C0)\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    Z3 = forward_propagation(X, parameters, n_y)\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss = cost)\n",
        "    \n",
        "    # Initialize all the variables globally\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "     \n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            minibatch_cost = 0.\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \"\"\"\n",
        "                # Run the session to execute the optimizer and the cost\n",
        "                # The feedict should contain a minibatch for (X,Y)\n",
        "                \"\"\"\n",
        "                _ , temp_cost = sess.run(fetches=[optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                \n",
        "                minibatch_cost += temp_cost / num_minibatches\n",
        "                \n",
        "\n",
        "            # Print the cost every 5 epoch\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
        "            if print_cost == True and epoch % 1 == 0:\n",
        "                costs.append(minibatch_cost)\n",
        "        \n",
        "        \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        predict_op = tf.argmax(input=Z3, axis=1)\n",
        "        correct_prediction = tf.equal(predict_op, tf.argmax(input=Y, axis=1))\n",
        "        \n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, \"float\"))\n",
        "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
        "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
        "        print(\"Train Accuracy:\", train_accuracy)\n",
        "        print(\"Test Accuracy:\", test_accuracy)\n",
        "                \n",
        "        return train_accuracy, test_accuracy, parameters"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uClMrCTrcrZk",
        "outputId": "7ceffa36-83db-48f9-d0fc-8654ab91a82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "# training the model\n",
        "\n",
        "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-3f684d38c54e>:40: flatten (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-3f684d38c54e>:44: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "Cost after epoch 0: 1.133566\n",
            "Cost after epoch 5: 0.211377\n",
            "Cost after epoch 10: 0.164185\n",
            "Cost after epoch 15: 0.141699\n",
            "Cost after epoch 20: 0.135304\n",
            "Cost after epoch 25: 0.130344\n",
            "Cost after epoch 30: 0.124696\n",
            "Cost after epoch 35: 0.119544\n",
            "Cost after epoch 40: 0.119500\n",
            "Cost after epoch 45: 0.119305\n",
            "Cost after epoch 50: 0.115165\n",
            "Cost after epoch 55: 0.114399\n",
            "Cost after epoch 60: 0.111381\n",
            "Cost after epoch 65: 0.111593\n",
            "Cost after epoch 70: 0.109206\n",
            "Cost after epoch 75: 0.111440\n",
            "Cost after epoch 80: 0.110954\n",
            "Cost after epoch 85: 0.106052\n",
            "Cost after epoch 90: 0.106815\n",
            "Cost after epoch 95: 0.106092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxddX3/8df7brNlZrLMJGQjIRCEgAsYFdcfFfQH1IJ7xVqttaX6qNal/fmgrT9c+qAPl9pW+7Bafy7U1mpRqwZEsFIUURDCFgkQCAGyETLZJjOZ9c58fn+ccyd3JpPJJORmkjnv5+NxH9x7zrnnfM+ccN/3u5zvVURgZmbZlZvqApiZ2dRyEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CGzakfRySeumuhxmJwoHgR1Vkp6QdOFUliEifhERz5rKMlRIOl/S5mN0rAskPSypR9ItkpZMsO3SdJue9D0Xjln/QUnbJO2V9DVJdVXrXiLpTkldktZIelktz8tqz0FgJxxJ+akuA4ASx8X/Q5LagP8C/i8wG1gN/OcEb/kWcC8wB/hr4LuS2tN9/W/gSuACYAmwDPh4um42cB3wGWAm8GngOkmzjv5Z2bFyXPwjtulPUk7SlZIek7RT0rXph0pl/XfSb6Cdkm6VdFbVumskfVHSDZL2Ab+V1jz+Iv1G2inpPyXVp9uP+hY+0bbp+g9LekrSVkl/JCkknXaQ8/iZpKsl/RLoAZZJeqekh9JvyBsk/Um6bRPwY2CBpO70seBQf4sj9HpgbUR8JyL6gI8Bz5V0xjjncDpwLvDRiOiNiO8BvwHekG7yDuCrEbE2InYDfwP8QbruJcC29DhDEfHvQEd6fDtBOQjsWHkf8FrgfwELgN3AF6rW/xhYDswF7gG+Oeb9bwWuBpqB29JlbwYuAk4BnsP+D6vxjLutpIuADwEXAqcB50/iXH4fuCIty5PAduA1QAvwTuAfJJ0bEfuAi4GtETEjfWydxN9ihKSTJe2Z4PHWdNOzgPsr70uP/Vi6fKyzgA0R0VW17P6qbUftK30+T9KcSrHGFhM4e7zy24mhMNUFsMx4N/DeiNgMIOljwEZJvx8R5Yj4WmXDdN1uSa0R0Zku/mFE/DJ93icJ4PPpByuSrgOeN8HxD7btm4GvR8TaqmP/3iHO5ZrK9qkfVT3/uaSfAC8nCbTxTPi3qN4wIjaSNMEcygySb+bVOknCarxtO8fZduFB1leeNwO3k9RwLge+SxLQpwKNkyijHadcI7BjZQnw/co3WeAhYIjkm2Ze0ifTppK9wBPpe9qq3r9pnH1uq3reQ/IBdjAH23bBmH2Pd5yxRm0j6WJJd0jalZ7bJYwu+1gH/VtM4tgH001SI6nWAnQdwbZj11eed0XETuAyklrU0yS1rJ8Cx6RD3GrDQWDHyibg4oiYWfWoj4gtJN8qLyNpnmkFlqbvqW6CqNU0uU8Bi6peL57Ee0bKko6m+R7wd8C8iJgJ3MD+so9X7on+FqOkTUPdEzwqtZe1wHOr3tdE8k197dh9psuWSaquLTy3attR+0qfP52GABHx84h4QUTMJmkmOwO4c5zj2AnCQWC1UJRUX/UoAF8CrlY6pFFSu6TL0u2bgX5gJ0kTw98ew7JeC7xT0pmSGklG3RyOElBH0ixTlnQx8Oqq9U8DcyS1Vi2b6G8xSkRsrOpfGO9R6Uv5PnC2pDekHeFXAWsi4uFx9vkIcB/w0fT6vI6k3+R76SbfAN4laYWkmcBHgGsq75d0jqSipBaSANwUETcdxt/MjjMOAquFG4DeqsfHgM8Bq4CfSOoC7gBelG7/DZJO1y3Ag+m6YyIifgx8HrgFWF917P5Jvr8L+DOSQNlNUrtZVbX+YZKhmhvSpqAFTPy3ONLz6CAZ9XN1Wo4XAW+prJf0JUlfqnrLW4CV6bafBN6Y7oOIuJFkWOgtwEaSa/PRqvd+GNhBUrOZD7zumZTdpp78wzRm+0k6E3gAqBvbcWs2XblGYJkn6XWS6pTcFPUp4DqHgGWJg8AM/oTkXoDHSEbvvGdqi2N2bLlpyMws41wjMDPLuBPuzuK2trZYunTpVBfDzOyEcvfdd++IiPbx1p1wQbB06VJWr1491cUwMzuhSHryYOvcNGRmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxmUmCO56Yhef/ck6BoeGp7ooZmbHlcwEwb0bd/NP/7OegbKDwMysWmaCoJBLTtU1AjOz0TITBMVCJQg826qZWbXsBEEu+S1x1wjMzEbLThDkk1Mtu0ZgZjZKZoKgkE9qBAOuEZiZjZKZIBipEQw7CMzMqmUuCAbLbhoyM6uWmSCoNA0NukZgZjZKZoKgNFIjcBCYmVXLTBAU0uGj5WE3DZmZVctMEFRuKPOoITOz0bITBDnfR2BmNp7sBEHBdxabmY0nM0HgSefMzMaXmSAoeYoJM7NxZSYIRu4jcI3AzGyUzATByJ3FHj5qZjZKhoIgrRH4hjIzs1EyFASedM7MbDyZCYL9fQRuGjIzq5aZICh6+KiZ2bgyEwS5nMjn5CAwMxujZkEg6WuStkt64CDrJenzktZLWiPp3FqVpaKQk+8jMDMbo5Y1gmuAiyZYfzGwPH1cAXyxhmUBkpvKPOmcmdloNQuCiLgV2DXBJpcB34jEHcBMSfNrVR5IOoxdIzAzG20q+wgWApuqXm9Olx1A0hWSVkta3dHRccQHLOZz7iMwMxvjhOgsjogvR8TKiFjZ3t5+xPtJgsA1AjOzalMZBFuAxVWvF6XLaqaY96ghM7OxpjIIVgFvT0cPnQd0RsRTtTxgIZ/zncVmZmMUarVjSd8CzgfaJG0GPgoUASLiS8ANwCXAeqAHeGetylJRzOcYKLtpyMysWs2CICIuP8T6AP60VscfTzEv1wjMzMY4ITqLjxaPGjIzO1CmgqCQk0cNmZmNkakgKBVylF0jMDMbJVNB4BqBmdmBMhUE7iMwMzuQg8DMLOMyFgSi7B+vNzMbJVNBUMjn/OP1ZmZjZCoIivkcg64RmJmNkrEg8KRzZmZjZSoICrmcf5jGzGyMTAVBsSD/VKWZ2RjZCoKc7yw2MxsrW0GQzzEcMOQOYzOzEZkKgkJeAO4wNjOrkqkgKOWT03UQmJntl6kgqNQIPHLIzGy/TAVB0TUCM7MDZCwI0j4CdxabmY3IWBCkNQLPN2RmNiJTQVBIg8A/YG9mtl+mgqA0MnzUTUNmZhWZCoJCzp3FZmZjZSoIioVKELhGYGZWka0gyPnOYjOzsbIVBGmNwDeUmZntl6kgKLhGYGZ2gEwFge8sNjM7UEaDwE1DZmYVNQ0CSRdJWidpvaQrx1l/sqRbJN0raY2kS2pZnpFJ53xDmZnZiJoFgaQ88AXgYmAFcLmkFWM2+whwbUScA7wF+OdalQf2T0M94CkmzMxG1LJG8EJgfURsiIgB4NvAZWO2CaAlfd4KbK1heapqBG4aMjOrqGUQLAQ2Vb3enC6r9jHgbZI2AzcA7xtvR5KukLRa0uqOjo4jLpA7i83MDjTVncWXA9dExCLgEuDfJB1Qpoj4ckSsjIiV7e3tR3ywYs6dxWZmY9UyCLYAi6teL0qXVXsXcC1ARNwO1ANttSpQseD7CMzMxqplENwFLJd0iqQSSWfwqjHbbAQuAJB0JkkQHHnbzyFUJp0rOwjMzEbULAgiogy8F7gJeIhkdNBaSZ+QdGm62Z8DfyzpfuBbwB9ERM3abSq/UDbgpiEzsxGFWu48Im4g6QSuXnZV1fMHgZfWsgzVJFHIyTUCM7MqU91ZfMwV8zn3EZiZVclcEBTy8qghM7MqmQuCUj7nKSbMzKpkLggKeTFYdo3AzKwic0FQzOcYdI3AzGxENoPAfQRmZiMyFwQePmpmNlrmgsDDR83MRstgEHj4qJlZtQwGgWsEZmbVMhcEhbwou0ZgZjYic0FQzOcYcI3AzGxEJoPAdxabme2XwSDwncVmZtUyFwQF31lsZjZK5oKg5FFDZmajZC4IkjuL3TRkZlaRuSAoFlwjMDOrlr0gyPnOYjOzatkLAvcRmJmNkrkgKORz7iMwM6syqSCQ9KbJLDsRlPJiYGiYCIeBmRlMvkbwl5Ncdtwr5JNTHhp2EJiZARQmWinpYuASYKGkz1etagHKtSxYrRTTICgPB4X8FBfGzOw4MGEQAFuB1cClwN1Vy7uAD9aqULVUzAuAgaFh6otOAjOzCYMgIu4H7pf0HxExCCBpFrA4InYfiwIebYVcEgTuMDYzS0y2j+C/JbVImg3cA/w/Sf9Qw3LVTLGQnLKHkJqZJSYbBK0RsRd4PfCNiHgRcEHtilU7xZyDwMys2mSDoCBpPvBm4PoalqfmioWkach3F5uZJSYbBJ8AbgIei4i7JC0DHq1dsWqnkNYIyq4RmJkBkwyCiPhORDwnIt6Tvt4QEW841PskXSRpnaT1kq48yDZvlvSgpLWS/uPwin/4KsNH/XOVZmaJyd5ZvEjS9yVtTx/fk7ToEO/JA18ALgZWAJdLWjFmm+UkN6a9NCLOAj5wRGdxGCrDRz1qyMwsMdmmoa8Dq4AF6eO6dNlEXgisT2sPA8C3gcvGbPPHwBcqQ1EjYvtkC36kKjUCdxabmSUmGwTtEfH1iCinj2uA9kO8ZyGwqer15nRZtdOB0yX9UtIdki4ab0eSrpC0WtLqjo6OSRZ5fIW8O4vNzKpNNgh2SnqbpHz6eBuw8ygcvwAsB84HLie5P2Hm2I0i4ssRsTIiVra3Hyp/JlZyjcDMbJTJBsEfkgwd3QY8BbwR+INDvGcLsLjq9aJ0WbXNwKqIGIyIx4FHSIKhZgojcw05CMzM4PCGj74jItojYi5JMHz8EO+5C1gu6RRJJeAtJP0M1X5AUhtAUhtJU9GGSZbpiIzMNVR205CZGUw+CJ5TPbdQROwCzpnoDRFRBt5Lcv/BQ8C1EbFW0ickXZpudhNJs9ODwC3A/4mIo9HkdFBF1wjMzEY51OyjFTlJsyphkM45dMj3RsQNwA1jll1V9TyAD6WPY8KjhszMRptsEHwWuF3Sd9LXbwKurk2Raqsy+6hHDZmZJSYVBBHxDUmrgVemi14fEQ/Wrli1U/Lso2Zmo0y2RkD6wX9CfvhX8+8RmJmNNtnO4mmj4D4CM7NRMhcE+28oc43AzAwyGASFkUnnXCMwM4MsBsHIqCEHgZkZZDAIJFHMi8FhNw2ZmUEGgwCSm8oGy64RmJlBRoOgkBNl1wjMzICMBkGpkPNPVZqZpTIZBIVczqOGzMxSmQyCYkG+j8DMLJXNIMjlPHzUzCyVzSDIOwjMzCoyGQSFvDzpnJlZKpNBUMx71JCZWUVGg8A1AjOziowGgfsIzMwqMhkEhXzOcw2ZmaUyGQTFnDzXkJlZKptBkM9RHnYQmJlBRoPAw0fNzPbLZBCUPHzUzGxEJoPANQIzs/0yGQQePmpmtp+DwMws4zIaBJ6G2sysIpNBUPDwUTOzETUNAkkXSVonab2kKyfY7g2SQtLKWpanImkaCiJcKzAzq1kQSMoDXwAuBlYAl0taMc52zcD7gV/XqixjFXMC8A/Ym5lR2xrBC4H1EbEhIgaAbwOXjbPd3wCfAvpqWJZRioXktN1hbGZW2yBYCGyqer05XTZC0rnA4oj40UQ7knSFpNWSVnd0dDzjghXSGoE7jM3MprCzWFIO+Hvgzw+1bUR8OSJWRsTK9vb2Z3zskmsEZmYjahkEW4DFVa8XpcsqmoGzgZ9JegI4D1h1LDqMCzkHgZlZRS2D4C5guaRTJJWAtwCrKisjojMi2iJiaUQsBe4ALo2I1TUsEwBtM0oAPNV5zLolzMyOWzULgogoA+8FbgIeAq6NiLWSPiHp0loddzLOXtgKwNotnVNZDDOz40KhljuPiBuAG8Ysu+og255fy7JUm99az+ymEg9s2XusDmlmdtzK5J3FkjhrQQu/cY3AzCybQQBJ89AjT3fRXx6a6qKYmU2p7AbBglbKw8Ej27qnuihmZlMqs0Hw7LTD+IGtbh4ys2zLbBAsnt1Ac32BB9xPYGYZl9kgkMTZC1odBGaWeZkNAoCzF7bw0LYu32FsZpmW8SBoZaA8zPrt7jA2s+zKfBAAbh4ys0zLdBCcMqeJplKetVt9h7GZZVemgyCXEyt8h7GZZVymgwCS5qEHt+5lyD9baWYZ5SBY0Erv4BCPPN011UUxM5sSmQ+Cly9vIyf48QPbprooZmZTIvNBMLelnvOWzWHVfVuIcPOQmWVP5oMA4LLnLeCJnT3uNDazTHIQABedNZ9iXqy6b+tUF8XM7JhzEACtjUXOf9Zcrluz1aOHzCxzHASpS5+7gKf39nPn47umuihmZseUgyB14ZnzaCzlWXX/lqkuipnZMeUgSDWU8rx6xTxu+M02BsqejdTMssNBUOWy5y2ks3eQG9f6ngIzyw4HQZVXnN7O6fNm8PmbH3WnsZllhoOgSj4n3n/B6azf3s31azyU1MyywUEwxsVnn8QZJzXzOdcKzCwjHARj5HLiAxcuZ0PHPo8gMrNMcBCM49UrTuLM+S187qePUvbvGZvZNOcgGEcuJz544XKe2NnDJ3/8sCejM7NpzUFwEK9aMY+3v3gJX7ntca7+0UMOAzObtgpTXYDjlSQ+fulZ5CS+ctvjDEVw1WtWIGmqi2ZmdlTVtEYg6SJJ6yStl3TlOOs/JOlBSWsk3SxpSS3Lc7gk8dHfWcEfvvQUvv7LJ/j0TeumukhmZkddzWoEkvLAF4BXAZuBuyStiogHqza7F1gZET2S3gN8GvjdWpXpSEji/77mTPrKQ3zxZ4+xcGYDbzvvuMorM7NnpJY1ghcC6yNiQ0QMAN8GLqveICJuiYie9OUdwKIalueISeITl57FBWfM5aofPsBPH3x6qotkZnbU1DIIFgKbql5vTpcdzLuAH4+3QtIVklZLWt3R0XEUizh5hXyOf3rrOZy9sJX3fetebnzgKXcgm9m0cFyMGpL0NmAl8Jnx1kfElyNiZUSsbG9vP7aFq9JYKvDVd7yARbMaePe/38Mln7+NGx94imHfgWxmJ7BaBsEWYHHV60XpslEkXQj8NXBpRPTXsDxHRXtzHT9+/8v5+zc/l/7BId797/fw6n+8lWtXb6K/PDTVxTMzO2yqVfOGpALwCHABSQDcBbw1ItZWbXMO8F3gooh4dDL7XblyZaxevboGJT58Q8PB9Wu28i8/38CDT+1lXksdf/SyZfzeeSfTWPLIXDM7fki6OyJWjruulu3cki4B/hHIA1+LiKslfQJYHRGrJP0UeDbwVPqWjRFx6UT7PJ6CoCIiuG39Dr7088f45fqdzGkq8cevWMbbzlvCjDoHgplNvSkLglo4HoOg2t1P7uJzN6/n1kc6aCjmufjsk3j9uYt48alzyOd8M5qZTQ0HwRS4f9Mevn3XJq5fs5WuvjKnzZ3Bp97wbJ6/ZPZUF83MMshBMIX6Boe4ae02Pn3jOrZ29vKOFy/lAxcup5jPMRxBXSFPqXBcDN4ys2nMQXAc6O4v85kbH+YbdzxJ9Z+8VMixcsksXnpaGy9f3sbZC1rJuQnJzI4yB8Fx5N6Nu7l9w07yEvmc2NbZxy8f28lDT+0FYHZTiVcsb+MVp7ezcslsFs9u8ER3ZvaMTRQEHtJyjJ1z8izOOXnWAct3dPdz26M7+PkjHdz6SAc/uC/5zeQ5TSVWLGgBYKA8zHAEzfVFZjYWmdNU4vR5zZy9sJXlc2dQyLuJycwOn4PgONE2o47XnrOQ156zkOHh4OFtXdy7aTf3PLmHR7d3kZMoFXLkc+LpvX2s29bFju5++svJL6jVFXK8YOlsXnF6Gy87rZ3hCLbs6eWpPb0sn9fMecs8asnMxuemoRPY0HDw+I59rN3ayX2b9nDbozt4dHv3uNu2zShx8dnzmdVYZOOuHjbu6qGprsDzFs/kOYtmsmJBC/Nb6kf6J7bu6eX2x3aydU8vMxuLtDaWaG0oMqMuT1NdgfYZdcyZUXcsT9fMngH3EWTI1j293Pn4LuqLORbObGRuSx13P7mb69ds5eaHtjM4NMz81gZOnt3Int5BHnm6i6F0rqT6Yo6lc5roGxziiZ09hzgSPH/JLH772fN51Yp5nNRaTzFtmtq9b4CHt3WxfnsXu/YNsqd3gO6+MgtnNfCsec2cflIzy9qajqjvo7u/THlomJmNpcN+r1mWOQgMSIayVpqYKnoGyqzdupd127p4fMc+NnR0k8/lOG/ZbF5yahunzm1ib2+Zzt4BOnsH6e4fYl9/mQ0d3fzoN9tGOrkBmusK1BVz7OgeGHXc5roCjXV5tnf1j4yYmt9az4VnzuOVZ84lJ/Hkzn08ubMn6QOpK9BUV6CxrkBDMU99MceGjn384tEO7tm4h6HhYFlbE+cumcVZC1qY31rP3JZ6Gkt5dnYP0NHVT8/AEHNmlGibUce8ljpOaqk/oA8lIg4Io937Brhjw04Wz27kzPktbk6zacNBYDXzWEc3v3psJ7u6B9jdM0Df4BDL2ps446QWTp/XzJwZpZGaQu/AEOu3d7N2aye3rNvOrY/soHdw/0R99cUcxVyO7oEyY/9ZSvDsha28fHkbTXUF7nlyD/ds3M2ufaND52AKObFoVgNzm+vZ3TNAR3c/XX1lTm1v4jmLZnJKWxO3P7aT2zfsHKkhNdcXeOHS2Zy7ZBbPXtjKWQta2Ly7l1+l2+3o6mdwaJjycFBXyNHeXMecphKzm+qY2Zh06Lc2FGmpL9LSUCCfy9HVN0hXX5n+8hClfJ66tN+nu79Md3+Zrr5BOnuTR1dfmaHhICI5/5Na6jl5TiOLZjXQUl+kvpinsZRndlPSbCeJiGBH9wBb9vSyr7+clG8o2DdQZm9fmb29gzSW8iyf28xpc2cwr6XuiGpmEUF3f5nm+uKE2/QNDlNfzHnk23HAQWDHpb7BIVY/sZtSIcfSOY20NycfSsPDQc/gED0DZfoGhukdHKK9uY7ZTaObgyKCnfsG2NbZx/auPnoGhmifUUdbcx0NxTy79iUf+E939rFxVw9P7uqho6uf2Y0l2pvraKorsG7bXtZs7mTnvgGWtTVx0dkn8coz5rJlTy93bNjJrzfsYsOOfQeU/Vnzmlk8u5FSQRRyOXoGhtjR3c+O7n729AzS3V8+4r9LPida6gs01xcp5EVOYmg42Lqnd2RwwFjFvJjdVKKzd5C+wfG3GU9OUFfIU1fM0VxfYG5zPfNa6mipLzIwNMzgUFDIicWzGzmlrZGGYoHb1nfws3UdbN7dy0kt9Txv8UyedVIz27v6eXxHN5t29dLZO8i+NNCLeTGnqY625hL5XI6IYGg4KA8Fg8PDDA4N0z6jjmed1Mzp85qZ31pPQympDVYCp7u/zPa9/TzW0c1jHd3s6B6gmE9qtw3FPLMaS8yZUaKxVGBv7yB7egfpGxxiZmOJthnJ9W6fUZf8t7mO+a0NzGosjvx727a3jyd39tDVN0hfeZi+wSF2dg+wvauP7V391OVzo967ZE4jJ89ppKlUoDf9t9rdV2Z3zyCdvQMMlIepL+apL+ZHgr6nP/nSc9rcGZzS1kSpkGNv3yDrtnWxcWcPjaV88sWhochJrfXMaSod1QB1EJhNICLY21umpaEw7v94nb2DrN3Sydqte5nXWs+Ll82hvXnijvLBoWE6ewfZ0zNIV98ge/uSvo3mtHZQV8gzUB6mvzxEeThpDptRX2BGXfIYrxwRQUdXP5vTb/s9A8kH0K59g0kIdfXT0lBk8awGFs5qpKW+QCGfo5gXjaUCLQ0FWuqLdPWVeXR7F+u3d9PRlYw86xscYm/vINu7+nl6bx9dfWWK+Rx1hRz95WG2dvaO1NIaS3lecmobz13UyqPbu7lv0x427uphdlOJpXMaWTqniZmNJWbU5WkoFdjbN8iOrn527hugPBzkBTmJQl4U8jkK6f00657uYk/P4IR/1zlNJU6dO4O5zXWUh4KBoWH29ZfZ3TPArn2D9AyUaW1IamL1xTy7ewbY0dXPvoEDp4ivK+Rom1E3avTdWDPqCrQ31zE4NMz2rn4GDrLd4SrkxKymEh1dB595v1TIMa+ljmIuqVEH8IELl3PZ8yb6fa+D830EZhOQRGvjwZs4WhuKvOS0Nl5yWtuk91nMJx8ybUdxZJUk5rYk/SHPRH0xT3tzHS85dfLn018eYtOuHjp7y5y9sIW6Qv6A9WOXHa5K0O3oHqB3cIjegSEkaErDsW1G6YgHCfQMlNnRNUBHdx9P7+1nW2cf2/b2sX1vH+3NdSyZ08TSOU20NhRpKOWoKyRNbk1VswdXvjBs2dPLxl1Jn1bPwBCNpaSJbkZ9gZmNJWY2FKkr5OkrD9E3kAR95RyGhoNHt3fxyNNdPL23n2XtTZx5UgtL5jTSXx5mb+8gu3sG2dbZy1NpGYeG9/dlzWmqzUg91wjMzDJgohqBb0U1M8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGXfC3VAmqQN48gjf3gbsOIrFOVFk8byzeM6QzfPO4jnD4Z/3kohoH2/FCRcEz4Sk1Qe7s246y+J5Z/GcIZvnncVzhqN73m4aMjPLOAeBmVnGZS0IvjzVBZgiWTzvLJ4zZPO8s3jOcBTPO1N9BGZmdqCs1QjMzGwMB4GZWcZlJggkXSRpnaT1kq6c6vLUgqTFkm6R9KCktZLeny6fLem/JT2a/nfWVJf1aJOUl3SvpOvT16dI+nV6vf9T0pH9tNVxTNJMSd+V9LCkhyS9OCPX+oPpv+8HJH1LUv10u96SviZpu6QHqpaNe22V+Hx67msknXu4x8tEEEjKA18ALgZWAJdLWjG1paqJMvDnEbECOA/40/Q8rwRujojlwM3p6+nm/cBDVa8/BfxDRJwG7AbeNSWlqq3PATdGxBnAc0nOf1pfa0kLgT8DVkbE2UAeeAvT73pfA1w0ZtnBru3FwPL0cQXwxcM9WCaCAHghsD4iNkTEAPBt4LIpLtNRFxFPRcQ96fMukg+GhSTn+q/pZv8KvHZqSlgbkhYBvw18JX0t4JXAd9NNpuM5twKvAL4KEBEDEbGHaX6tUwWgQVIBaASeYhUuHykAAAYXSURBVJpd74i4Fdg1ZvHBru1lwDcicQcwU9L8wzleVoJgIbCp6vXmdNm0JWkpcA7wa2BeRDyVrtoGzJuiYtXKPwIfBobT13OAPRFRTl9Px+t9CtABfD1tEvuKpCam+bWOiC3A3wEbSQKgE7ib6X+94eDX9hl/vmUlCDJF0gzge8AHImJv9bpIxgtPmzHDkl4DbI+Iu6e6LMdYATgX+GJEnAPsY0wz0HS71gBpu/hlJEG4AGjiwCaUae9oX9usBMEWYHHV60XpsmlHUpEkBL4ZEf+VLn66UlVM/7t9qspXAy8FLpX0BEmT3ytJ2s5npk0HMD2v92Zgc0T8On39XZJgmM7XGuBC4PGI6IiIQeC/SP4NTPfrDQe/ts/48y0rQXAXsDwdWVAi6VxaNcVlOurStvGvAg9FxN9XrVoFvCN9/g7gh8e6bLUSEX8ZEYsiYinJdf2fiPg94Bbgjelm0+qcASJiG7BJ0rPSRRcADzKNr3VqI3CepMb033vlvKf19U4d7NquAt6ejh46D+isakKanIjIxAO4BHgEeAz466kuT43O8WUk1cU1wH3p4xKSNvObgUeBnwKzp7qsNTr/84Hr0+fLgDuB9cB3gLqpLl8Nzvd5wOr0ev8AmJWFaw18HHgYeAD4N6Buul1v4FskfSCDJLW/dx3s2gIiGRX5GPAbkhFVh3U8TzFhZpZxWWkaMjOzg3AQmJllnIPAzCzjHARmZhnnIDAzyzgHgR03JP0q/e9SSW89yvv+q/GOVSuSXivpqhrt+68OvdVh7/PZkq452vu1E4OHj9pxR9L5wF9ExGsO4z2F2D/XzHjruyNixtEo3yTL8yvg0ojY8Qz3c8B51epcJP0U+MOI2Hi0923HN9cI7LghqTt9+kng5ZLuS+eez0v6jKS70vnW/yTd/nxJv5C0iuTuUiT9QNLd6Xz1V6TLPkkyW+V9kr5Zfaz0bszPpHPb/0bS71bt+2dV8/1/M72TFUmfVPKbD2sk/d0453E60F8JAUnXSPqSpNWSHknnR6r8hsKkzqtq3+Ody9sk3Zku+5d02nUkdUu6WtL9ku6QNC9d/qb0fO+XdGvV7q8juTvbsmaq76Dzw4/KA+hO/3s+6R3C6esrgI+kz+tI7qY9Jd1uH3BK1baVuy0bSO48nVO973GO9Qbgv0nmtZ9HMoXB/HTfnSTztuSA20nu3J4DrGN/bXrmOOfxTuCzVa+vAW5M97Oc5E7R+sM5r/HKnj4/k+QDvJi+/mfg7enzAH4nff7pqmP9Blg4tvwkc/ZcN9X/Dvw49o/KJE1mx7NXA8+RVJlLppXkA3UAuDMiHq/a9s8kvS59vjjdbucE+34Z8K2IGCKZ1OvnwAuAvem+NwNIug9YCtwB9AFfVfJraNePs8/5JFNEV7s2IoaBRyVtAM44zPM6mAuA5wN3pRWWBvZPRjZQVb67gVelz38JXCPpWpJJ2yq2k8zoaRnjILATgYD3RcRNoxYmfQn7xry+EHhxRPRI+hnJN+8j1V/1fAgoRERZ0gtJPoDfCLyXZMbTar0kH+rVxnbGBZM8r0MQ8K8R8ZfjrBuMiMpxh0j/f4+Id0t6EcmP+dwt6fkRsZPkb9U7yePaNOI+AjsedQHNVa9vAt6TTrGNpNOV/AjLWK3A7jQEziD5uc6Kwcr7x/gF8Ltpe307ya9+3Xmwgin5rYfWiLgB+CDJT0SO9RBw2phlb5KUk3QqyQRp6w7jvMaqPpebgTdKmpvuY7akJRO9WdKpEfHriLiKpOZSmcL4dJLmNMsY1wjseLQGGJJ0P0n7+udImmXuSTtsOxj/pwhvBN4t6SGSD9o7qtZ9GVgj6Z5Ipqmu+D7wYuB+km/pH46IbWmQjKcZ+KGkepJv4x8aZ5tbgc9KUtU38o0kAdMCvDsi+iR9ZZLnNdaoc5H0EeAnknIks1X+KfDkBO//jKTlaflvTs8d4LeAH03i+DbNePioWQ1I+hxJx+tP0/H510fEdw/xtikjqQ74OfCymGAYrk1Pbhoyq42/Jflh9RPFycCVDoFsco3AzCzjXCMwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OM+/+J5pwnTmEeLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.9662\n",
            "Test Accuracy: 0.9634\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}